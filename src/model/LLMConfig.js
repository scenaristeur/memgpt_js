/**
 * OpenAI Assistants API
 * No description provided (generated by Openapi Generator https://github.com/openapitools/openapi-generator)
 *
 * The version of the OpenAPI document: 0.1.0
 * 
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 *
 */

import ApiClient from '../ApiClient';

/**
 * The LLMConfig model module.
 * @module model/LLMConfig
 * @version 0.1.0
 */
class LLMConfig {
    /**
     * Constructs a new <code>LLMConfig</code>.
     * @alias module:model/LLMConfig
     * @param model {String} LLM model name. 
     * @param modelEndpointType {String} The endpoint type for the model.
     * @param modelEndpoint {String} The endpoint for the model.
     * @param contextWindow {Number} The context window size for the model.
     */
    constructor(model, modelEndpointType, modelEndpoint, contextWindow) { 
        
        LLMConfig.initialize(this, model, modelEndpointType, modelEndpoint, contextWindow);
    }

    /**
     * Initializes the fields of this object.
     * This method is used by the constructors of any subclasses, in order to implement multiple inheritance (mix-ins).
     * Only for internal use.
     */
    static initialize(obj, model, modelEndpointType, modelEndpoint, contextWindow) { 
        obj['model'] = model;
        obj['model_endpoint_type'] = modelEndpointType;
        obj['model_endpoint'] = modelEndpoint;
        obj['context_window'] = contextWindow;
    }

    /**
     * Constructs a <code>LLMConfig</code> from a plain JavaScript object, optionally creating a new instance.
     * Copies all relevant properties from <code>data</code> to <code>obj</code> if supplied or a new instance if not.
     * @param {Object} data The plain JavaScript object bearing properties of interest.
     * @param {module:model/LLMConfig} obj Optional instance to populate.
     * @return {module:model/LLMConfig} The populated <code>LLMConfig</code> instance.
     */
    static constructFromObject(data, obj) {
        if (data) {
            obj = obj || new LLMConfig();

            if (data.hasOwnProperty('model')) {
                obj['model'] = ApiClient.convertToType(data['model'], 'String');
            }
            if (data.hasOwnProperty('model_endpoint_type')) {
                obj['model_endpoint_type'] = ApiClient.convertToType(data['model_endpoint_type'], 'String');
            }
            if (data.hasOwnProperty('model_endpoint')) {
                obj['model_endpoint'] = ApiClient.convertToType(data['model_endpoint'], 'String');
            }
            if (data.hasOwnProperty('model_wrapper')) {
                obj['model_wrapper'] = ApiClient.convertToType(data['model_wrapper'], 'String');
            }
            if (data.hasOwnProperty('context_window')) {
                obj['context_window'] = ApiClient.convertToType(data['context_window'], 'Number');
            }
        }
        return obj;
    }

    /**
     * Validates the JSON data with respect to <code>LLMConfig</code>.
     * @param {Object} data The plain JavaScript object bearing properties of interest.
     * @return {boolean} to indicate whether the JSON data is valid with respect to <code>LLMConfig</code>.
     */
    static validateJSON(data) {
        // check to make sure all required properties are present in the JSON string
        for (const property of LLMConfig.RequiredProperties) {
            if (!data.hasOwnProperty(property)) {
                throw new Error("The required field `" + property + "` is not found in the JSON data: " + JSON.stringify(data));
            }
        }
        // ensure the json data is a string
        if (data['model'] && !(typeof data['model'] === 'string' || data['model'] instanceof String)) {
            throw new Error("Expected the field `model` to be a primitive type in the JSON string but got " + data['model']);
        }
        // ensure the json data is a string
        if (data['model_endpoint_type'] && !(typeof data['model_endpoint_type'] === 'string' || data['model_endpoint_type'] instanceof String)) {
            throw new Error("Expected the field `model_endpoint_type` to be a primitive type in the JSON string but got " + data['model_endpoint_type']);
        }
        // ensure the json data is a string
        if (data['model_endpoint'] && !(typeof data['model_endpoint'] === 'string' || data['model_endpoint'] instanceof String)) {
            throw new Error("Expected the field `model_endpoint` to be a primitive type in the JSON string but got " + data['model_endpoint']);
        }
        // ensure the json data is a string
        if (data['model_wrapper'] && !(typeof data['model_wrapper'] === 'string' || data['model_wrapper'] instanceof String)) {
            throw new Error("Expected the field `model_wrapper` to be a primitive type in the JSON string but got " + data['model_wrapper']);
        }

        return true;
    }


}

LLMConfig.RequiredProperties = ["model", "model_endpoint_type", "model_endpoint", "context_window"];

/**
 * LLM model name. 
 * @member {String} model
 */
LLMConfig.prototype['model'] = undefined;

/**
 * The endpoint type for the model.
 * @member {String} model_endpoint_type
 */
LLMConfig.prototype['model_endpoint_type'] = undefined;

/**
 * The endpoint for the model.
 * @member {String} model_endpoint
 */
LLMConfig.prototype['model_endpoint'] = undefined;

/**
 * @member {String} model_wrapper
 */
LLMConfig.prototype['model_wrapper'] = undefined;

/**
 * The context window size for the model.
 * @member {Number} context_window
 */
LLMConfig.prototype['context_window'] = undefined;






export default LLMConfig;

